module:
  title: "Создание автономных агентных систем с LLM"
  description: >
    В этом модуле студенты узнают, что такое LLM-агенты, как они могут планировать действия
    и использовать внешние инструменты. Мы соберём простого агента, который способен решать
    многошаговые задачи: формулировать план, обращаться к функциям (например, API или калькулятору)
    и выдавать финальный результат.
  goals:
    - Понять концепцию LLM-агента и отличие от обычного чат-бота.
    - Научиться подключать инструменты к модели (function calling, API).
    - Реализовать простой цикл работы агента (планирование → действие → результат).
    - Освоить базовые приёмы повышения устойчивости и расширения агентов.

  submodules:
    - title: "Концепция LLM-агента"
      description: >
        Разберём, чем агент отличается от простого чат-бота: агент умеет сам планировать действия,
        использовать инструменты и работать в несколько шагов.
      learning_objectives:
        - Освоить архитектуру агента: планировщик, исполнитель, память.
        - Понять различие между статичным ботом и динамическим агентом.
        - Познакомиться с примерами AutoGPT, BabyAGI.
      key_terms:
        - "LLM-агент"
        - "Планировщик"
        - "Исполнитель"
        - "AutoGPT"
        - "BabyAGI"
      steps:
        - "Примеры: чат-бот (ответ в один шаг) vs агент (несколько шагов)."
        - "Разбор архитектуры: планировщик, исполнитель, память."
        - "Краткий обзор проектов AutoGPT и BabyAGI."
      pedagogy_notes: >
        Пояснить на аналогии: чат-бот = собеседник, агент = ассистент, который сам думает,
        какие шаги выполнить. Сделать акцент на «самостоятельности» агента.
      milestone_demo: >
        Студент видит пример агента, который решает задачу через несколько шагов
        (например: поиск информации → генерация ответа).
      practical_outcomes:
        - "Объяснить, чем агент отличается от чат-бота."
        - "Назвать основные компоненты агентной архитектуры."
      check_questions:
        - "Какие три основных компонента входят в архитектуру LLM-агента?"
        - "Почему агент может решать более сложные задачи, чем чат-бот?"
      further_reading:
        - "AutoGPT GitHub"
        - "BabyAGI GitHub"

    - title: "Интеграция инструментов"
      description: >
        Изучим, как подключать внешние инструменты: API, калькулятор, поиск.
        Это позволяет модели выполнять действия, которых у неё самой нет.
      learning_objectives:
        - Освоить концепцию function calling.
        - Научиться подключать API как инструмент для агента.
        - Реализовать простой внешний инструмент (например, калькулятор).
      key_terms:
        - "Инструмент (tool)"
        - "Function calling"
        - "API"
      steps:
        - "Что такое инструменты для модели и зачем они нужны."
        - "Пример: калькулятор как внешний инструмент."
        - "Реализация вызова API из агента."
      pedagogy_notes: >
        Сравнить с человеком: «если ты чего-то не знаешь — ты гуглишь или считаешь».
        Агенту тоже нужны такие «способности».
      milestone_demo: >
        Агент решает задачу с помощью подключённого калькулятора (LLM выбирает, когда вызвать функцию).
      practical_outcomes:
        - "Реализовать первый инструмент для агента."
        - "Научиться связывать LLM с API."
      check_questions:
        - "Что такое function calling в контексте LLM?"
        - "Зачем агенту нужны инструменты?"
      further_reading:
        - "OpenAI Function Calling docs"
        - "LangChain: Tools"

    - title: "Реализация простого агентного цикла"
      description: >
        Соберём цикл, в котором агент получает задачу, планирует шаги, вызывает инструменты
        и формирует финальный ответ.
      learning_objectives:
        - Освоить базовую логику работы агентного цикла.
        - Научиться связывать планирование и выполнение.
        - Реализовать прототип агента (ReAct-стиль).
      key_terms:
        - "Агентный цикл"
        - "ReAct"
        - "Память агента"
      steps:
        - "Пример задачи, требующей нескольких шагов."
        - "Реализация цикла «Задача → Действие → Результат → Новый шаг»."
        - "Подключение нескольких инструментов."
        - "Формирование финального ответа."
      pedagogy_notes: >
        Показать агентный цикл «вживую» — лог (план → действие → результат).
        Студенты видят, как агент рассуждает и принимает решения.
      milestone_demo: >
        Агент автоматически решает задачу: ищет данные и использует их в ответе.
      practical_outcomes:
        - "Собрать базовый агентный цикл."
        - "Научиться отлаживать поведение агента."
      check_questions:
        - "Что означает ReAct-подход?"
        - "Какие шаги выполняет агент в цикле?"
      further_reading:
        - "ReAct paper"
        - "LangChain Agents"

    - title: "Устойчивость и расширение агента (опционально)"
      description: >
        Обсудим, как сделать агентов более надёжными: добавить валидацию, ограничить неверные действия,
        использовать память и хранить контекст.
      learning_objectives:
        - Освоить базовые приёмы повышения устойчивости агента.
        - Научиться использовать память между сессиями.
        - Понять основы мультиагентных систем.
      key_terms:
        - "Валидация"
        - "Память агента"
        - "Мультиагентные системы"
      steps:
        - "Проблемы нестабильности агентов."
        - "Методы: валидация, ограничения, проверка результатов."
        - "Использование памяти (долгосрочное хранение контекста)."
        - "Кратко: мультиагентные системы."
      pedagogy_notes: >
        Показать, что агент «по умолчанию» может ошибаться,
        но инженер может добавить «страховочные рельсы».
      milestone_demo: >
        Агент решает задачу в несколько итераций, сохраняя промежуточные результаты.
      practical_outcomes:
        - "Добавить простую проверку результата в цикл агента."
        - "Реализовать использование памяти."
      check_questions:
        - "Какие методы можно использовать для стабилизации агента?"
        - "Зачем агенту нужна память?"
      further_reading:
        - "LangChain Memory"
        - "Мультиагентные эксперименты в AI"
