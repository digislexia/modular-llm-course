module:
  title: "Продвинутый промпт-инжиниринг и работа с моделями через OpenRouter"
  description: >
    В этом модуле студенты переходят от базовых приёмов промпт-инжиниринга к продвинутым стратегиям,
    учатся использовать сильные и слабые стороны разных моделей через OpenRouter,
    а также знакомятся с методами проверки и оптимизации качества ответов.
  goals:
    - Освоить сложные стратегии промптов (комбинации приёмов, ReAct, Tree-of-Thought).
    - Научиться выбирать подходящую модель под задачу с помощью OpenRouter.
    - Освоить AutoRouter и fallback для многомодельных приложений.
    - Понять, как проверять и оптимизировать качество генерации (LLM-as-a-judge, экономия токенов).
    - Научиться управлять контекстом в длинных диалогах и преодолевать ограничения окна контекста.

  submodules:
    - title: "Продвинутые стратегии промптов"
      description: >
        Разберём, как комбинировать техники (few-shot, chain-of-thought, system prompts) и использовать
        более сложные стратегии — Tree-of-Thought и ReAct — для управления рассуждениями модели.
      learning_objectives:
        - Научиться комбинировать разные техники в одном запросе.
        - Освоить подходы ReAct и Tree-of-Thought для сложных задач.
        - Понять, как строить шаблоны промптов для разных сценариев.
      key_terms:
        - "Tree-of-Thought"
        - "ReAct (Reason + Act)"
        - "Комбинации промптов"
        - "Шаблоны промптов"
      steps:
        - "Повторение: какие приёмы мы уже знаем (few-shot, CoT, system prompts)."
        - "Пример комбинирования: few-shot + chain-of-thought."
        - "Разбор стратегии ReAct (рассуждение + действие)."
        - "Tree-of-Thought: разветвлённое рассуждение."
        - "Шаблоны промптов для разных задач (ответ, план, проверка)."
      pedagogy_notes: >
        Показать реальные кейсы, где простой CoT не работает, а Tree-of-Thought даёт лучший результат.
        Разбирать примеры пошагово, как это делает преподаватель CS50.
      milestone_demo: >
        Студент создаёт промпт в стиле ReAct: модель рассуждает и вызывает условный инструмент
        (например, калькулятор или поиск).
      practical_outcomes:
        - "Написать комбинированный промпт (few-shot + CoT)."
        - "Применить ReAct для решения задачи."
        - "Построить шаблон промпта для собственной задачи."
      check_questions:
        - "В чём отличие Chain-of-Thought от Tree-of-Thought?"
        - "Что даёт стратегия ReAct по сравнению с обычным промптом?"
        - "Приведите пример, когда нужно комбинировать несколько техник."
      further_reading:
        - "ReAct: Synergizing Reasoning and Acting in Language Models (2022)"
        - "Tree-of-Thought: Deliberate Problem Solving with LLMs (2023)"

    - title: "Многомодельность и роутинг в OpenRouter"
      description: >
        Изучим, как сравнивать разные модели через OpenRouter, выбирать подходящие под задачу
        и использовать AutoRouter и fallback для повышения надёжности приложений.
      learning_objectives:
        - Освоить вызовы разных моделей через единый API OpenRouter.
        - Научиться сравнивать модели по качеству, скорости и стоимости.
        - Понять, как работает AutoRouter и fallback.
        - Реализовать простое правило выбора модели под задачу.
      key_terms:
        - "OpenRouter"
        - "AutoRouter"
        - "Fallback"
        - "Многомодельность"
      steps:
        - "Запрос к одной задаче через несколько моделей (GPT-4, Claude, Mistral)."
        - "Сравнение ответов по качеству, стилю и длине."
        - "Разбор AutoRouter: автоматический выбор модели."
        - "Fallback: резервный сценарий при недоступности модели."
        - "Создание мини-фреймворка: выбор модели по типу задачи."
      pedagogy_notes: >
        Делать упор на инженерное мышление: студент сам формулирует критерии, какая модель лучше
        для конкретного случая. Добавить аналогию с «выбором инструмента под задачу».
      milestone_demo: >
        Студент создаёт функцию, которая в зависимости от типа задачи (код, креатив, резюме)
        выбирает подходящую модель в OpenRouter.
      practical_outcomes:
        - "Сравнить несколько моделей на одной задаче."
        - "Реализовать простой роутинг моделей."
        - "Использовать AutoRouter для оптимизации."
      check_questions:
        - "Зачем может понадобиться fallback?"
        - "В чём преимущество AutoRouter?"
        - "Как определить, какая модель лучше подходит под задачу?"
      further_reading:
        - "Документация OpenRouter: AutoRouter"
        - "Сравнение моделей LLM: обзоры Hugging Face"

    - title: "Контроль качества и оптимизация"
      description: >
        Научимся проверять и улучшать ответы моделей: использовать LLM для оценки LLM,
        вводить критерии качества и оптимизировать стоимость запросов.
      learning_objectives:
        - Освоить концепцию LLM-as-a-judge.
        - Научиться проверять ответы по заданным критериям (точность, стиль).
        - Освоить базовые методы оптимизации токенов.
      key_terms:
        - "LLM-as-a-judge"
        - "Критерии качества"
        - "Токенизация"
        - "Оптимизация запросов"
      steps:
        - "Определение критериев качества (правильность, полнота, стиль)."
        - "Пример: одна модель генерирует ответ, другая проверяет."
        - "Добавление автоматических проверок (например, ответ должен содержать ≥3 пункта)."
        - "Оптимизация токенов: сокращение промптов, кэширование, резюмирование контекста."
      pedagogy_notes: >
        Объяснить через аналогию «модель как редактор, который проверяет текст другой модели».
        Сделать акцент, что это дешевле и быстрее, чем ручная проверка.
      milestone_demo: >
        Студент создаёт пайплайн: одна модель отвечает на вопрос,
        вторая проверяет, соответствует ли ответ заданным критериям.
      practical_outcomes:
        - "Написать промпт для модели-«судьи»."
        - "Добавить автоматическую проверку качества ответа."
        - "Оптимизировать промпт для экономии токенов."
      check_questions:
        - "Что означает LLM-as-a-judge?"
        - "Какие критерии качества ответа можно задать?"
        - "Как можно уменьшить количество токенов в запросе?"
      further_reading:
        - "Evals: инструменты OpenAI для оценки LLM"
        - "Evidently AI: тестирование LLM в продакшене"

    - title: "Управление контекстом в длинных диалогах"
      description: >
        Изучим стратегии работы с ограничениями окна контекста: резюмирование диалогов,
        скользящее окно, компрессия истории разговора и выборочное сохранение ключевой информации.
      learning_objectives:
        - Понять, как ограничения контекстного окна влияют на качество диалога.
        - Освоить техники резюмирования предыдущих сообщений.
        - Научиться применять стратегию скользящего окна.
        - Реализовать систему управления контекстом для долгих разговоров.
      key_terms:
        - "Окно контекста"
        - "Резюмирование диалога"
        - "Скользящее окно"
        - "Компрессия контекста"
        - "Токеновый лимит"
      steps:
        - "Демонстрация проблемы: что происходит при переполнении контекста."
        - "Стратегия 1: Резюмирование — сжатие истории диалога в краткое изложение."
        - "Стратегия 2: Скользящее окно — сохранение последних N сообщений."
        - "Стратегия 3: Выборочное сохранение — сохранение важных частей разговора."
        - "Комбинирование стратегий: гибридный подход для разных сценариев."
        - "Реализация простого менеджера контекста."
      pedagogy_notes: >
        Показать реальный пример: диалог становится слишком длинным и модель «забывает» начало.
        Объяснить через аналогию с кратковременной памятью человека: «нужно записывать важное».
      milestone_demo: >
        Студент создаёт чат-бот, который может вести диалог из 50+ сообщений,
        автоматически управляя контекстом без потери качества.
      practical_outcomes:
        - "Реализовать автоматическое резюмирование диалога."
        - "Создать систему скользящего окна контекста."
        - "Построить менеджер контекста для чат-приложения."
      check_questions:
        - "Что происходит, когда диалог превышает лимит контекста?"
        - "В чём разница между резюмированием и скользящим окном?"
        - "Как определить, какую информацию стоит сохранить в контексте?"
        - "Какие стратегии лучше подходят для разных типов диалогов?"
      further_reading:
        - "OpenAI: Managing conversation context"
        - "Anthropic: Context window strategies"
        - "LangChain: Memory management"
