module:
  title: "Retrieval-Augmented Generation (RAG) — обогащение LLM внешними данными"
  description: >
    В этом модуле студенты узнают, как соединять LLM с внешними источниками знаний,
    чтобы получать более точные и фактические ответы. Мы построим собственный RAG-пайплайн:
    от эмбеддингов и векторных баз до интеграции поиска и генерации ответа.
  goals:
    - Понять, зачем нужен RAG и как он работает.
    - Освоить создание векторных представлений текстов (эмбеддинги).
    - Научиться строить векторный индекс и выполнять семантический поиск.
    - Интегрировать поиск с LLM для генерации ответов.
    - Получить первый работающий QA-бот на основе собственных документов.

  submodules:
    - title: "Зачем нужен RAG?"
      description: >
        Разберём проблему «галлюцинаций» моделей и ограниченности встроенных знаний,
        поймём, как подключение к внешним данным решает эту задачу.
      learning_objectives:
        - Понять ограничения LLM в знаниях и актуальности.
        - Освоить концепцию retrieval + generation.
        - Уметь объяснить пользу RAG простыми словами.
      key_terms:
        - "RAG (Retrieval-Augmented Generation)"
        - "Retriever"
        - "Generator"
        - "Галлюцинации модели"
      steps:
        - "Примеры ошибок LLM без доступа к базе знаний."
        - "Принцип RAG: поиск (retriever) + генерация (generator)."
        - "Как меняется качество ответов с RAG."
      pedagogy_notes: >
        Показать реальные примеры: вопрос о свежей информации, на который LLM «галлюцинирует»,
        и как RAG исправляет ситуацию.
      milestone_demo: >
        Сравнение ответов модели «с RAG» и «без RAG» на один и тот же вопрос.
      practical_outcomes:
        - "Уметь объяснить RAG непрофессионалу."
        - "Понимать, почему RAG уменьшает галлюцинации."
      check_questions:
        - "Что означает термин RAG?"
        - "Почему LLM не могут знать всю актуальную информацию?"
        - "Какие компоненты входят в архитектуру RAG?"
      further_reading:
        - "Meta AI: Introducing Retrieval-Augmented Generation (2020)"
        - "Haystack RAG tutorials"

    - title: "Эмбеддинги и векторные базы"
      description: >
        Научимся превращать текст в векторные представления и хранить их во векторной базе
        для семантического поиска.
      learning_objectives:
        - Освоить принцип эмбеддингов.
        - Научиться строить и сохранять векторный индекс.
        - Понять разницу между ключевым словом и семантическим поиском.
      key_terms:
        - "Эмбеддинг"
        - "Векторное пространство"
        - "Семантический поиск"
        - "FAISS / Qdrant / Weaviate"
      steps:
        - "Что такое эмбеддинг: представление текста в виде чисел."
        - "Как получить эмбеддинги через API."
        - "Сохранение векторов в базе (пример FAISS или Qdrant)."
        - "Поиск ближайших соседей (nearest neighbors)."
      pedagogy_notes: >
        Объяснить через аналогию: «каждый текст превращается в точку в многомерном пространстве,
        и похожие тексты оказываются рядом».
      milestone_demo: >
        Студент выполняет запрос и видит, как система находит релевантные документы
        по смыслу, а не по ключевым словам.
      practical_outcomes:
        - "Построить эмбеддинги для своего набора документов."
        - "Выполнить первый семантический поиск."
      check_questions:
        - "Что такое эмбеддинг простыми словами?"
        - "Почему поиск по вектору лучше ключевого слова?"
        - "Какие популярные библиотеки используют для векторного поиска?"
      further_reading:
        - "Hugging Face: Sentence Transformers"
        - "Qdrant Documentation"

    - title: "Интеграция поиска и генерации"
      description: >
        Соединим поиск по базе знаний и LLM: модель будет использовать найденные документы
        для генерации точных и обоснованных ответов.
      learning_objectives:
        - Научиться подавать найденные документы в промпт.
        - Освоить базовый пайплайн RAG end-to-end.
        - Построить простого QA-бота по своим данным.
      key_terms:
        - "QA-бот"
        - "Контекст в промпте"
        - "End-to-end пайплайн"
      steps:
        - "Формирование промпта: вопрос + найденные документы."
        - "Передача промпта в LLM."
        - "Получение ответа с обоснованием."
        - "Сборка пайплайна в виде функции или простого приложения."
      pedagogy_notes: >
        Сначала показать схему (поток: запрос → поиск → генерация),
        потом собрать минимальный прототип, как в Fast.ai (learning by building).
      milestone_demo: >
        Студент получает работающего бота: задаёт вопрос по своим документам
        и получает релевантный ответ с цитатой.
      practical_outcomes:
        - "Собрать пайплайн RAG end-to-end."
        - "Создать простого QA-бота на базе своих документов."
      check_questions:
        - "Что нужно добавить в промпт, чтобы модель использовала найденные данные?"
        - "Почему RAG снижает количество галлюцинаций?"
        - "В чём разница между retriever и generator?"
      further_reading:
        - "LangChain: RAG tutorials"
        - "Pinecone + OpenAI: Building QA bots"

    - title: "Улучшение и расширение RAG (опционально)"
      description: >
        Обсудим дополнительные приёмы улучшения качества: ранжирование документов,
        оптимизация промпта с контекстом, обновление базы знаний.
      learning_objectives:
        - Понять базовые методы повышения качества поиска.
        - Освоить настройку количества документов в промпте.
        - Научиться обновлять и расширять базу знаний.
      key_terms:
        - "Ранжирование документов"
        - "Top-N retrieval"
        - "Актуализация базы"
      steps:
        - "Избыточные документы и как их фильтровать."
        - "Оптимизация шаблона промпта."
        - "Как добавлять новые данные в базу знаний."
      pedagogy_notes: >
        Объяснить, что реальный RAG — это не «один раз сделал и забыл»,
        а система, которую можно улучшать и масштабировать.
      practical_outcomes:
        - "Настроить количество документов для контекста."
        - "Добавить новые документы в базу."
      check_questions:
        - "Что может ухудшить качество работы RAG?"
        - "Как можно улучшить промпт с контекстом?"
      further_reading:
        - "Haystack advanced RAG"
        - "Weaviate hybrid search"
