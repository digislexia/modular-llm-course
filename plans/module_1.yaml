module:
  title: "Введение в LLM и базовый промпт-инжиниринг"
  description: >
    В этом модуле студенты познакомятся с основами больших языковых моделей (LLM),
    научатся подключаться к ним через API и освоят базовые техники промпт-инжиниринга.
    Цель — создать первое простое приложение с использованием LLM и понять,
    как формулировка запросов влияет на ответы модели.
  goals:
    - Понять, что такое большие языковые модели и как они устроены на концептуальном уровне.
    - Научиться подключаться к LLM через API и выполнять базовые запросы.
    - Освоить принципы базового промпт-инжиниринга для управляемых ответов.
    - Создать первое простое AI-приложение с использованием LLM.

  submodules:
    - title: "Основы и устройство LLM"
      description: >
        Введение в концепцию больших языковых моделей: история развития NLP,
        архитектура трансформеров, понятие параметрической памяти, возможности и ограничения LLM.
      learning_objectives:
        - Понять эволюцию NLP-моделей от статистических подходов к трансформерам.
        - Осознать ключевые идеи архитектуры Transformer (self-attention).
        - Понять сильные и слабые стороны LLM.
      key_terms:
        - "Языковая модель"
        - "Transformer"
        - "Self-attention"
        - "Контекстное окно"
        - "Галлюцинации модели"
      steps:
        - "Обзор истории NLP: от n-грамм к трансформерам."
        - "Объяснение архитектуры трансформеров простыми словами (аналогия с вниманием человека)."
        - "Примеры реальных задач, которые решают LLM."
        - "Ограничения: контекст, искажения, галлюцинации."
      pedagogy_notes: >
        Объяснить через аналогии (например, «мозг и внимание»), добавить простые визуальные образы,
        подчеркнуть как LLM «предсказывает следующее слово». 
      practical_outcomes:
        - "Уметь объяснить, что такое LLM, простыми словами."
        - "Уметь назвать сильные и слабые стороны LLM."
      check_questions:
        - "Что делает механизм self-attention в модели Transformer?"
        - "Почему LLM могут «галлюцинировать»?"
        - "Что такое контекстное окно и почему оно важно?"
      further_reading:
        - "Статья «Attention is All You Need» (2017)"
        - "Блог Hugging Face: Введение в трансформеры"

    - title: "Подключение к модели и первое приложение"
      description: >
        Практика работы с LLM: установка окружения, выполнение первого запроса к модели,
        создание простого приложения для генерации текста.
      learning_objectives:
        - Настроить окружение для работы с LLM через API.
        - Выполнить первый запрос и получить ответ от модели.
        - Создать минимальное приложение (например, чат-бот).
      key_terms:
        - "API"
        - "Запрос (prompt)"
        - "Ответ (completion)"
        - "Токен"
      steps:
        - "Установка зависимостей и подключение к API (например, OpenRouter)."
        - "Выполнение первого запроса к модели."
        - "Разбор структуры запроса и ответа (prompt → completion)."
        - "Создание мини-приложения (чат-бот или суммаризатор)."
      milestone_demo: >
        Первый «вау»-момент: студент отправляет свой запрос и видит осмысленный ответ модели в консоли
        или в мини-приложении.
      practical_outcomes:
        - "Запустить первую программу с использованием LLM."
        - "Создать минимальный чат-бот или суммаризатор текста."
      check_questions:
        - "Что такое токен и как он связан с запросом?"
        - "Какая разница между prompt и completion?"
        - "Почему важно учитывать ограничения контекстного окна?"
      further_reading:
        - "Документация OpenRouter API"
        - "Примеры из OpenAI Cookbook"

    - title: "Базовый промпт-инжиниринг"
      description: >
        Освоение техник составления запросов: прямые вопросы, инструкции, few-shot.
        Понимание того, как разные формулировки влияют на результат.
      learning_objectives:
        - Научиться формулировать ясные запросы.
        - Использовать инструкции для управления стилем ответа.
        - Применять метод few-shot для обучения модели в контексте.
      key_terms:
        - "Промпт"
        - "Инструкция"
        - "Few-shot learning"
        - "Стиль ответа"
      steps:
        - "Примеры плохих и хороших запросов: как формулировка влияет на результат."
        - "Использование инструкций для задания роли и стиля модели."
        - "Few-shot: добавление примеров в запрос."
        - "Практика: чат-бот с заданным стилем общения."
      pedagogy_notes: >
        Привести примеры в виде диалога (один и тот же вопрос, разные промпты → разные ответы).
        Сделать акцент на том, что промпт = интерфейс общения с моделью.
      practical_outcomes:
        - "Создать промпт, который меняет стиль ответа модели."
        - "Применить few-shot для управления выводом."
      check_questions:
        - "Что такое few-shot и в чем его преимущество?"
        - "Как можно управлять стилем ответа модели?"
        - "Приведите пример плохого промпта и объясните, почему он неэффективен."
      further_reading:
        - "DeepLearning.AI: курс по промпт-инжинирингу"
        - "OpenAI: Примеры эффективных промптов"
