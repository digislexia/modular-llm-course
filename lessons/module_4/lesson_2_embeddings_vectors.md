# –£—Ä–æ–∫ 2: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã

## –í–≤–µ–¥–µ–Ω–∏–µ

–í –ø—Ä–µ–¥—ã–¥—É—â–µ–º —É—Ä–æ–∫–µ –º—ã —É–∑–Ω–∞–ª–∏, —á—Ç–æ RAG —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ Retriever –∏ Generator. –°–µ–≥–æ–¥–Ω—è –º—ã –ø–æ–≥—Ä—É–∑–∏–º—Å—è –≤ —Å–µ—Ä–¥—Ü–µ Retriever ‚Äî **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏** –∏ **–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö**.

–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –∑–∞–¥–∞—á—É: —É –≤–∞—Å 10 000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞—é—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî "–∫—É–ø–∏—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω" –∏ "–ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ —Å–º–∞—Ä—Ç—Ñ–æ–Ω" –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–º—ã—Å–ª, –Ω–æ —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞. –ö–∞–∫ –∏—Å–∫–∞—Ç—å –ø–æ —Å–º—ã—Å–ª—É?

–û—Ç–≤–µ—Ç: **—ç–º–±–µ–¥–¥–∏–Ω–≥–∏** ‚Äî –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–º—ã—Å–ª–∞" –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ.

## –¶–µ–ª–∏ —É—Ä–æ–∫–∞

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —É—Ä–æ–∫–∞ –≤—ã —Å–º–æ–∂–µ—Ç–µ:

- ‚úÖ –ü–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ —Ç–∞–∫–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –∫–∞–∫ –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç
- ‚úÖ –ü–æ–ª—É—á–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ API
- ‚úÖ –°–æ–∑–¥–∞–≤–∞—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
- ‚úÖ –ü—Ä–∏–º–µ–Ω—è—Ç—å chunking –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

## –ö–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã

- **–≠–º–±–µ–¥–¥–∏–Ω–≥ (Embedding)** ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
- **–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (Dimension)** ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∏—Å–µ–ª –≤ –≤–µ–∫—Ç–æ—Ä–µ (–æ–±—ã—á–Ω–æ 384-1536)
- **–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ** ‚Äî –º–µ—Ä–∞ –±–ª–∏–∑–æ—Å—Ç–∏ –¥–≤—É—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ (-1 –¥–æ 1)
- **–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö** ‚Äî —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
- **Chunking** ‚Äî —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

## 1. –ß—Ç–æ —Ç–∞–∫–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏

### –ê–Ω–∞–ª–æ–≥–∏—è: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–º—ã—Å–ª–∞

–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –∫–∞—Ä—Ç—É, –≥–¥–µ –∫–∞–∂–¥—ã–π –≥–æ—Ä–æ–¥ –∏–º–µ–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (—à–∏—Ä–æ—Ç–∞, –¥–æ–ª–≥–æ—Ç–∞). –ë–ª–∏–∑–∫–∏–µ –≥–æ—Ä–æ–¥–∞ ‚Äî –±–ª–∏–∑–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.

**–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–∞–∫ –∂–µ**, –Ω–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞:
- –ö–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—É—á–∞–µ—Ç "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã" –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
- –ü–æ—Ö–æ–∂–∏–µ –ø–æ —Å–º—ã—Å–ª—É —Ç–µ–∫—Å—Ç—ã ‚Üí –±–ª–∏–∑–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
- –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: –Ω–µ 2 (–∫–∞–∫ –Ω–∞ –∫–∞—Ä—Ç–µ), –∞ 384-1536 –∏–∑–º–µ—Ä–µ–Ω–∏–π

```
–ü—Ä–∏–º–µ—Ä (—É–ø—Ä–æ—â—ë–Ω–Ω–æ –¥–æ 3 –∏–∑–º–µ—Ä–µ–Ω–∏–π):

"–∫–æ—Ç —Å–ø–∏—Ç –Ω–∞ –¥–∏–≤–∞–Ω–µ"     ‚Üí [0.8, 0.2, 0.5]
"–∫–æ—à–∫–∞ –æ—Ç–¥—ã—Ö–∞–µ—Ç –Ω–∞ —Å–æ—Ñ–µ" ‚Üí [0.79, 0.21, 0.48]  ‚Üê –ë–ª–∏–∑–∫–æ!
"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python" ‚Üí [0.1, 0.9, 0.3] ‚Üê –î–∞–ª–µ–∫–æ!
```

### –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?

–ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, text-embedding-3-small –æ—Ç OpenAI):
1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç
2. –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã

```python
"–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!" ‚Üí [0.023, -0.041, 0.087, ..., 0.012]  # 1536 —á–∏—Å–µ–ª
```

### –ü—Ä–∞–∫—Ç–∏–∫–∞: –ü–µ—Ä–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏

```python
"""
–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OpenAI API.
"""

import os
import requests
import numpy as np
from dotenv import load_dotenv

load_dotenv()


def get_embedding(text: str, model: str = "text-embedding-3-small") -> list:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI API.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        model: –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        
    Returns:
        –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (—Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª)
    """
    api_key = os.getenv("OPENAI_API_KEY")
    
    # –ï—Å–ª–∏ –Ω–µ—Ç OpenAI –∫–ª—é—á–∞, –ø—Ä–æ–±—É–µ–º OpenRouter
    if not api_key:
        api_key = os.getenv("OPENROUTER_API_KEY")
        url = "https://openrouter.ai/api/v1/embeddings"
    else:
        url = "https://api.openai.com/v1/embeddings"
    
    response = requests.post(
        url,
        headers={
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        },
        json={
            "model": model,
            "input": text
        }
    )
    
    if response.status_code == 200:
        return response.json()["data"][0]["embedding"]
    else:
        raise Exception(f"–û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")


def cosine_similarity(vec1: list, vec2: list) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–≤—É—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤.
    
    –ó–Ω–∞—á–µ–Ω–∏—è:
        1.0 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏)
        0.0 = –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ (–Ω–µ —Å–≤—è–∑–∞–Ω—ã)
       -1.0 = –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    """
    vec1 = np.array(vec1)
    vec2 = np.array(vec2)
    
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    return dot_product / (norm1 * norm2)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø: –ü–æ—Ö–æ–∂–∏–µ –∏ —Ä–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("="*60)
print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í")
print("="*60)

# –¢–µ–∫—Å—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
texts = [
    "–ö–æ—Ç —Å–ø–∏—Ç –Ω–∞ –¥–∏–≤–∞–Ω–µ",           # 0
    "–ö–æ—à–∫–∞ –æ—Ç–¥—ã—Ö–∞–µ—Ç –Ω–∞ —Å–æ—Ñ–µ",        # 1 - –ø–æ—Ö–æ–∂–µ –Ω–∞ 0
    "–°–æ–±–∞–∫–∞ –∏–≥—Ä–∞–µ—Ç –≤–æ –¥–≤–æ—Ä–µ",        # 2 - –¥—Ä—É–≥–æ–µ –∂–∏–≤–æ—Ç–Ω–æ–µ
    "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python",    # 3 - —Å–æ–≤—Å–µ–º –¥—Ä—É–≥–∞—è —Ç–µ–º–∞
    "Python ‚Äî –ø–æ–ø—É–ª—è—Ä–Ω—ã–π —è–∑—ã–∫",      # 4 - –ø–æ—Ö–æ–∂–µ –Ω–∞ 3
]

print("\n–ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤...")
embeddings = []
for i, text in enumerate(texts):
    emb = get_embedding(text)
    embeddings.append(emb)
    print(f"  [{i}] '{text[:30]}...' ‚Üí –≤–µ–∫—Ç–æ—Ä –∏–∑ {len(emb)} —á–∏—Å–µ–ª")

print(f"\n–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {len(embeddings[0])}")

# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä—ã
print("\n" + "-"*60)
print("–ú–ê–¢–†–ò–¶–ê –°–•–û–î–°–¢–í–ê (–∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ):")
print("-"*60)

for i in range(len(texts)):
    for j in range(len(texts)):
        sim = cosine_similarity(embeddings[i], embeddings[j])
        print(f"  [{i}]-[{j}]: {sim:.3f}", end="")
        if sim > 0.8 and i != j:
            print(" ‚Üê –ü–æ—Ö–æ–∂–∏!", end="")
        print()
    print()

print("="*60)
print("–ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø:")
print("="*60)
print("""
‚Ä¢ [0]-[1] –≤—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: –æ–±–∞ –ø—Ä–æ –∫–æ—Ç–∞/–∫–æ—à–∫—É –Ω–∞ –º–µ–±–µ–ª–∏
‚Ä¢ [3]-[4] –≤—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: –æ–±–∞ –ø—Ä–æ Python
‚Ä¢ [0]-[3] –Ω–∏–∑–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: –∫–æ—Ç vs –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ
""")
```

### üîç –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–µ–±—è

–ü—Ä–µ–∂–¥–µ —á–µ–º –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–æ–¥:
1. –ö–∞–∫–∏–µ –ø–∞—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤ –±—É–¥—É—Ç –∏–º–µ—Ç—å –≤—ã—Å–æ–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ?
2. –ö–∞–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –æ–∂–∏–¥–∞–µ—Ç–µ –º–µ–∂–¥—É "–∫–æ—Ç" –∏ "Python"?

<details>
<summary>–û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã</summary>

- [0] –∏ [1]: ~0.85-0.95 (–∫–æ—Ç/–∫–æ—à–∫–∞ –Ω–∞ –º–µ–±–µ–ª–∏)
- [3] –∏ [4]: ~0.80-0.90 (–æ–±–∞ –ø—Ä–æ Python)
- [0] –∏ [3]: ~0.15-0.30 (—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã)
- [2] –∏ [0]: ~0.50-0.65 (–æ–±–∞ –ø—Ä–æ –∂–∏–≤–æ—Ç–Ω—ã—Ö, –Ω–æ —Ä–∞–∑–Ω—ã—Ö)
</details>

## 2. –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏

–°–æ–∑–¥–∞–¥–∏–º —É–¥–æ–±–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤:

```python
"""
–ö–ª–∞—Å—Å EmbeddingGenerator –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏.
"""

import os
import json
import hashlib
import requests
import numpy as np
from typing import List, Dict, Optional
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()


class EmbeddingGenerator:
    """
    –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ API –≤—ã–∑–æ–≤–æ–≤.
    """
    
    def __init__(
        self, 
        model: str = "text-embedding-3-small",
        cache_dir: Optional[str] = ".embedding_cache"
    ):
        """
        Args:
            model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫—ç—à–∞ (None = –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è)
        """
        self.model = model
        self.cache_dir = Path(cache_dir) if cache_dir else None
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫—ç—à–∞
        if self.cache_dir:
            self.cache_dir.mkdir(exist_ok=True)
        
        # API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPENROUTER_API_KEY")
        if os.getenv("OPENAI_API_KEY"):
            self.api_url = "https://api.openai.com/v1/embeddings"
        else:
            self.api_url = "https://openrouter.ai/api/v1/embeddings"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "api_calls": 0,
            "cache_hits": 0,
            "total_tokens": 0
        }
    
    def _get_cache_key(self, text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        content = f"{self.model}:{text}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _get_from_cache(self, text: str) -> Optional[List[float]]:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞"""
        if not self.cache_dir:
            return None
        
        cache_file = self.cache_dir / f"{self._get_cache_key(text)}.json"
        if cache_file.exists():
            with open(cache_file, 'r') as f:
                self.stats["cache_hits"] += 1
                return json.load(f)
        return None
    
    def _save_to_cache(self, text: str, embedding: List[float]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ –∫—ç—à"""
        if not self.cache_dir:
            return
        
        cache_file = self.cache_dir / f"{self._get_cache_key(text)}.json"
        with open(cache_file, 'w') as f:
            json.dump(embedding, f)
    
    def get_embedding(self, text: str) -> List[float]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            
        Returns:
            –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = self._get_from_cache(text)
        if cached:
            return cached
        
        # –ó–∞–ø—Ä–æ—Å –∫ API
        response = requests.post(
            self.api_url,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "input": text
            }
        )
        
        if response.status_code != 200:
            raise Exception(f"API Error: {response.status_code} - {response.text}")
        
        data = response.json()
        embedding = data["data"][0]["embedding"]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats["api_calls"] += 1
        if "usage" in data:
            self.stats["total_tokens"] += data["usage"].get("total_tokens", 0)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self._save_to_cache(text, embedding)
        
        return embedding
    
    def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞—Ç—á–∏–Ω–≥ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        embeddings = []
        texts_to_fetch = []
        indices_to_fetch = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        for i, text in enumerate(texts):
            cached = self._get_from_cache(text)
            if cached:
                embeddings.append((i, cached))
            else:
                texts_to_fetch.append(text)
                indices_to_fetch.append(i)
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –≤ –∫—ç—à–µ (–±–∞—Ç—á–∞–º–∏ –ø–æ 100)
        batch_size = 100
        for batch_start in range(0, len(texts_to_fetch), batch_size):
            batch_texts = texts_to_fetch[batch_start:batch_start + batch_size]
            batch_indices = indices_to_fetch[batch_start:batch_start + batch_size]
            
            response = requests.post(
                self.api_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "input": batch_texts
                }
            )
            
            if response.status_code != 200:
                raise Exception(f"API Error: {response.status_code}")
            
            data = response.json()
            self.stats["api_calls"] += 1
            
            for j, item in enumerate(data["data"]):
                emb = item["embedding"]
                original_idx = batch_indices[j]
                original_text = batch_texts[j]
                
                embeddings.append((original_idx, emb))
                self._save_to_cache(original_text, emb)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∏–Ω–¥–µ–∫—Å—É
        embeddings.sort(key=lambda x: x[0])
        return [emb for _, emb in embeddings]
    
    def similarity(self, text1: str, text2: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏"""
        emb1 = np.array(self.get_embedding(text1))
        emb2 = np.array(self.get_embedding(text2))
        
        return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))
    
    def find_most_similar(
        self, 
        query: str, 
        candidates: List[str], 
        top_k: int = 5
    ) -> List[Dict]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            candidates: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ç–µ–∫—Å—Ç–æ–º –∏ score
        """
        query_emb = np.array(self.get_embedding(query))
        candidate_embs = self.get_embeddings_batch(candidates)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –≤—Å–µ—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        results = []
        for i, cand_emb in enumerate(candidate_embs):
            cand_emb = np.array(cand_emb)
            score = float(np.dot(query_emb, cand_emb) / 
                         (np.linalg.norm(query_emb) * np.linalg.norm(cand_emb)))
            results.append({
                "text": candidates[i],
                "score": score,
                "index": i
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
        results.sort(key=lambda x: x["score"], reverse=True)
        
        return results[:top_k]
    
    def get_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return self.stats.copy()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    print("="*60)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø EmbeddingGenerator")
    print("="*60)
    
    generator = EmbeddingGenerator()
    
    # –¢–µ—Å—Ç 1: –ë–∞–∑–æ–≤–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    print("\nüìä –¢–µ—Å—Ç 1: –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞")
    text = "Python ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"
    emb = generator.get_embedding(text)
    print(f"–¢–µ–∫—Å—Ç: '{text}'")
    print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(emb)}")
    print(f"–ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {emb[:5]}")
    
    # –¢–µ—Å—Ç 2: –°—Ö–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤
    print("\nüìä –¢–µ—Å—Ç 2: –°—Ö–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤")
    pairs = [
        ("–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"),
        ("–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ –ø–∏—Ü—Ü—ã"),
        ("–∫–æ—Ç", "–∫–æ—Ç—ë–Ω–æ–∫"),
        ("–∫–æ—Ç", "–∞–≤—Ç–æ–º–æ–±–∏–ª—å"),
    ]
    
    for text1, text2 in pairs:
        sim = generator.similarity(text1, text2)
        print(f"'{text1}' ‚Üî '{text2}': {sim:.3f}")
    
    # –¢–µ—Å—Ç 3: –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
    print("\nüìä –¢–µ—Å—Ç 3: –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤")
    candidates = [
        "–ö–∞–∫ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Python –Ω–∞ Windows",
        "–†–µ—Ü–µ–ø—Ç –±–æ—Ä—â–∞ —Å –º—è—Å–æ–º",
        "–û—Å–Ω–æ–≤—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
        "Python –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö",
        "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –Ω–æ—É—Ç–±—É–∫",
        "–í–≤–µ–¥–µ–Ω–∏–µ –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏",
    ]
    
    query = "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python"
    results = generator.find_most_similar(query, candidates, top_k=3)
    
    print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    for r in results:
        print(f"  {r['score']:.3f} - {r['text']}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {generator.get_stats()}")
```

## 3. –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

### –ó–∞—á–µ–º –Ω—É–∂–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –±–∞–∑–∞?

–ü—Ä–∏ 10 000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –∫–∞–∂–¥—ã–º –∑–∞–Ω–∏–º–∞–µ—Ç —Å–µ–∫—É–Ω–¥—ã. –ü—Ä–∏ 1 000 000 ‚Äî –º–∏–Ω—É—Ç—ã. –ù—É–∂–µ–Ω **–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π**.

**–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö** —Ä–µ—à–∞—é—Ç —ç—Ç—É –∑–∞–¥–∞—á—É:
- –ò–Ω–¥–µ–∫—Å–∏—Ä—É—é—Ç –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã ANN (Approximate Nearest Neighbors)
- –ü–æ–∏—Å–∫ –∑–∞ O(log n) –≤–º–µ—Å—Ç–æ O(n)

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫

| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –¢–∏–ø | –ü–ª—é—Å—ã | –ú–∏–Ω—É—Å—ã |
|------------|-----|-------|--------|
| **FAISS** | –õ–æ–∫–∞–ª—å–Ω–∞—è | –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è, –æ—Ç Meta | –ù–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ |
| **Chroma** | –õ–æ–∫–∞–ª—å–Ω–∞—è | –ü—Ä–æ—Å—Ç–æ–π API, –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å | –ú–µ–¥–ª–µ–Ω–Ω–µ–µ FAISS |
| **Qdrant** | –°–µ—Ä–≤–µ—Ä | –ü—Ä–æ–¥–∞–∫—à–µ–Ω-ready, —Ñ–∏–ª—å—Ç—Ä—ã | –ù—É–∂–µ–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä |
| **Pinecone** | –û–±–ª–∞–∫–æ | Managed, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å | –ü–ª–∞—Ç–Ω—ã–π |

–ú—ã –Ω–∞—á–Ω—ë–º —Å **FAISS** (–ø—Ä–æ—Å—Ç–æ—Ç–∞) –∏ –ø–æ–∫–∞–∂–µ–º **Chroma** (—É–¥–æ–±—Å—Ç–≤–æ).

### –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å FAISS

```python
"""
–ü—Ä–æ—Å—Ç–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ FAISS.
"""

import numpy as np
import faiss
from typing import List, Dict, Optional, Tuple
import json
from pathlib import Path


class SimpleVectorDB:
    """
    –ü—Ä–æ—Å—Ç–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ FAISS.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ, –ø–æ–∏—Å–∫ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫—É.
    """
    
    def __init__(self, dimension: int = 1536):
        """
        Args:
            dimension: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ (1536 –¥–ª—è text-embedding-3-small)
        """
        self.dimension = dimension
        
        # –°–æ–∑–¥–∞—ë–º FAISS –∏–Ω–¥–µ–∫—Å (L2 = –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ)
        # –î–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
        self.index = faiss.IndexFlatIP(dimension)  # Inner Product (–∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
        
        # –•—Ä–∞–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.documents: List[str] = []
        self.metadata: List[Dict] = []
    
    def _normalize(self, vectors: np.ndarray) -> np.ndarray:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        norms = np.linalg.norm(vectors, axis=1, keepdims=True)
        return vectors / norms
    
    def add(
        self, 
        texts: List[str], 
        embeddings: List[List[float]],
        metadata: Optional[List[Dict]] = None
    ):
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –±–∞–∑—É.
        
        Args:
            texts: –¢–µ–∫—Å—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            embeddings: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        if len(texts) != len(embeddings):
            raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        vectors = np.array(embeddings, dtype=np.float32)
        vectors = self._normalize(vectors)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏–Ω–¥–µ–∫—Å
        self.index.add(vectors)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.documents.extend(texts)
        
        if metadata:
            self.metadata.extend(metadata)
        else:
            self.metadata.extend([{}] * len(texts))
    
    def search(
        self, 
        query_embedding: List[float], 
        top_k: int = 5
    ) -> List[Dict]:
        """
        –ò—â–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.
        
        Args:
            query_embedding: –≠–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ scores
        """
        if self.index.ntotal == 0:
            return []
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        query = np.array([query_embedding], dtype=np.float32)
        query = self._normalize(query)
        
        # –ò—â–µ–º
        scores, indices = self.index.search(query, min(top_k, self.index.ntotal))
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx < 0:  # FAISS –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç -1 –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
                continue
            results.append({
                "text": self.documents[idx],
                "score": float(score),
                "index": int(idx),
                "metadata": self.metadata[idx]
            })
        
        return results
    
    def save(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞–∑—É –Ω–∞ –¥–∏—Å–∫"""
        path = Path(path)
        path.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å FAISS
        faiss.write_index(self.index, str(path / "index.faiss"))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open(path / "data.json", 'w', encoding='utf-8') as f:
            json.dump({
                "documents": self.documents,
                "metadata": self.metadata,
                "dimension": self.dimension
            }, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –ë–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {path}")
    
    def load(self, path: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É —Å –¥–∏—Å–∫–∞"""
        path = Path(path)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å
        self.index = faiss.read_index(str(path / "index.faiss"))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        with open(path / "data.json", 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.documents = data["documents"]
            self.metadata = data["metadata"]
            self.dimension = data["dimension"]
        
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    def __len__(self) -> int:
        return len(self.documents)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    from embedding_generator import EmbeddingGenerator  # –ò–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
    
    print("="*60)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø SimpleVectorDB")
    print("="*60)
    
    # –°–æ–∑–¥–∞—ë–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –±–∞–∑—É
    embedder = EmbeddingGenerator()
    db = SimpleVectorDB(dimension=1536)
    
    # –ü—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    documents = [
        "Python ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è",
        "JavaScript –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü",
        "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "SQL ‚Äî —è–∑—ã–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–º–∏ –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö",
        "Docker –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ø–∞–∫–æ–≤—ã–≤–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã",
        "Git ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç—Ä–æ–ª—è –≤–µ—Ä—Å–∏–π",
        "REST API ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –≤–µ–±-—Å–µ—Ä–≤–∏—Å–æ–≤",
        "Kubernetes –æ—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è",
    ]
    
    # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    print("\nüìä –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
    embeddings = embedder.get_embeddings_batch(documents)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = [{"category": "programming"} for _ in documents]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É
    db.add(documents, embeddings, metadata)
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(db)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ü–æ–∏—Å–∫
    print("\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫...")
    queries = [
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö?",
        "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π",
        "–Ø–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –≤–µ–±–∞",
    ]
    
    for query in queries:
        print(f"\nüìå –ó–∞–ø—Ä–æ—Å: '{query}'")
        query_emb = embedder.get_embedding(query)
        results = db.search(query_emb, top_k=3)
        
        for i, r in enumerate(results, 1):
            print(f"   {i}. [{r['score']:.3f}] {r['text'][:50]}...")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞
    print("\nüíæ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å...")
    db.save("test_db")
    
    db2 = SimpleVectorDB()
    db2.load("test_db")
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(db2)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
```

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Chroma

Chroma ‚Äî –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Å —É–¥–æ–±–Ω—ã–º API:

```python
"""
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Chroma –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
pip install chromadb
"""

import chromadb
from chromadb.utils import embedding_functions


def demo_chroma():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å Chroma"""
    
    # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç (–ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–π)
    client = chromadb.PersistentClient(path="./chroma_db")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–∏–ª–∏ —Å–≤–æ–∏)
    # openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    #     api_key="your-key",
    #     model_name="text-embedding-3-small"
    # )
    
    # –°–æ–∑–¥–∞—ë–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
    collection = client.get_or_create_collection(
        name="my_documents",
        # embedding_function=openai_ef  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    collection.add(
        documents=[
            "Python ‚Äî –æ—Ç–ª–∏—á–Ω—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è",
            "JavaScript –ø–æ–ø—É–ª—è—Ä–µ–Ω –¥–ª—è –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–µ–Ω—è–µ—Ç –º–∏—Ä",
        ],
        metadatas=[
            {"category": "python"},
            {"category": "javascript"},
            {"category": "ml"},
        ],
        ids=["doc1", "doc2", "doc3"]
    )
    
    # –ü–æ–∏—Å–∫
    results = collection.query(
        query_texts=["–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python"],
        n_results=2
    )
    
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:")
    for doc, dist in zip(results['documents'][0], results['distances'][0]):
        print(f"  [{dist:.3f}] {doc}")
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
    results_filtered = collection.query(
        query_texts=["—è–∑—ã–∫–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è"],
        n_results=2,
        where={"category": "python"}  # –¢–æ–ª—å–∫–æ Python
    )
    
    print("\n–° —Ñ–∏–ª—å—Ç—Ä–æ–º (—Ç–æ–ª—å–∫–æ Python):")
    for doc in results_filtered['documents'][0]:
        print(f"  {doc}")


if __name__ == "__main__":
    demo_chroma()
```

## 4. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ end-to-end

–û–±—ä–µ–¥–∏–Ω–∏–º –≤—Å—ë –≤ —Ä–∞–±–æ—Ç–∞—é—â—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞:

```python
"""
–ü–æ–ª–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞.
"""

import os
import numpy as np
from typing import List, Dict
from pathlib import Path


class SemanticSearch:
    """
    –°–∏—Å—Ç–µ–º–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º.
    """
    
    def __init__(self, embedding_generator, vector_db):
        """
        Args:
            embedding_generator: –≠–∫–∑–µ–º–ø–ª—è—Ä EmbeddingGenerator
            vector_db: –≠–∫–∑–µ–º–ø–ª—è—Ä SimpleVectorDB
        """
        self.embedder = embedding_generator
        self.db = vector_db
    
    def index_documents(
        self, 
        documents: List[str],
        metadata: List[Dict] = None
    ):
        """
        –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É.
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        print(f"üìä –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
        embeddings = self.embedder.get_embeddings_batch(documents)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É
        self.db.add(documents, embeddings, metadata)
        
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(self.db)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º –∏ score
        """
        # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedder.get_embedding(query)
        
        # –ò—â–µ–º –≤ –±–∞–∑–µ
        results = self.db.search(query_embedding, top_k)
        
        return results
    
    def search_with_threshold(
        self, 
        query: str, 
        threshold: float = 0.7,
        top_k: int = 10
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É score.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score (0-1)
            top_k: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        results = self.search(query, top_k)
        return [r for r in results if r["score"] >= threshold]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ü–û–õ–ù–´–ô –ü–†–ò–ú–ï–†: –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def load_sample_documents() -> List[Dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
    docs_path = Path(__file__).parent / "data" / "sample_docs.txt"
    
    if not docs_path.exists():
        # –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        return [
            {"text": "Python ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è", "source": "doc1"},
            {"text": "–°–ø–∏—Å–∫–∏ –≤ Python ‚Äî —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏", "source": "doc2"},
            {"text": "–°–ª–æ–≤–∞—Ä–∏ —Ö—Ä–∞–Ω—è—Ç –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ", "source": "doc3"},
            {"text": "–§—É–Ω–∫—Ü–∏–∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ def", "source": "doc4"},
            {"text": "–ö–ª–∞—Å—Å—ã —Å–æ–∑–¥–∞—é—Ç—Å—è –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º class", "source": "doc5"},
        ]
    
    documents = []
    current_doc = ""
    doc_num = 0
    
    with open(docs_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip() == "---":
                if current_doc.strip():
                    doc_num += 1
                    documents.append({
                        "text": current_doc.strip(),
                        "source": f"doc_{doc_num}"
                    })
                current_doc = ""
            else:
                current_doc += line
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
    if current_doc.strip():
        doc_num += 1
        documents.append({
            "text": current_doc.strip(),
            "source": f"doc_{doc_num}"
        })
    
    return documents


def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    
    print("="*70)
    print("–°–ò–°–¢–ï–ú–ê –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ü–û–ò–°–ö–ê")
    print("="*70)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    from embedding_generator import EmbeddingGenerator
    from vector_db import SimpleVectorDB
    
    embedder = EmbeddingGenerator()
    db = SimpleVectorDB(dimension=1536)
    search_engine = SemanticSearch(embedder, db)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    print("\nüìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    docs = load_sample_documents()
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º
    texts = [d["text"] for d in docs]
    metadata = [{"source": d["source"]} for d in docs]
    search_engine.index_documents(texts, metadata)
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
    print("\n" + "="*70)
    print("–ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –ü–û–ò–°–ö")
    print("="*70)
    print("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è)")
    
    while True:
        query = input("\nüîç –ó–∞–ø—Ä–æ—Å: ").strip()
        
        if query.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'q']:
            break
        
        if not query:
            continue
        
        results = search_engine.search(query, top_k=5)
        
        print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for i, r in enumerate(results, 1):
            score_bar = "‚ñà" * int(r['score'] * 10) + "‚ñë" * (10 - int(r['score'] * 10))
            print(f"\n{i}. [{score_bar}] {r['score']:.3f}")
            print(f"   {r['text'][:100]}...")
            if r['metadata']:
                print(f"   üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫: {r['metadata'].get('source', 'N/A')}")


if __name__ == "__main__":
    main()
```

## 5. Chunking ‚Äî –Ω–∞—Ä–µ–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

### –ü–æ—á–µ–º—É –Ω—É–∂–µ–Ω chunking?

- –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ª—É—á—à–µ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö (200-500 —Ç–æ–∫–µ–Ω–æ–≤)
- –î–ª–∏–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Ä–∞–∑–º—ã–≤–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫—É
- –ü—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω—É–∂–µ–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç

### –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ chunking

```python
"""
–†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏.
"""

import re
from typing import List, Dict


class TextChunker:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏.
    """
    
    @staticmethod
    def chunk_by_chars(
        text: str, 
        chunk_size: int = 1000, 
        overlap: int = 200
    ) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∏–º–≤–æ–ª–æ–≤ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            overlap: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
        """
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            chunk = text[start:end]
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–∫–æ–Ω—á–∏—Ç—å –Ω–∞ –≥—Ä–∞–Ω–∏—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if end < len(text):
                last_period = chunk.rfind('.')
                last_newline = chunk.rfind('\n')
                break_point = max(last_period, last_newline)
                
                if break_point > chunk_size // 2:
                    chunk = text[start:start + break_point + 1]
                    end = start + break_point + 1
            
            chunks.append(chunk.strip())
            start = end - overlap
        
        return [c for c in chunks if c]
    
    @staticmethod
    def chunk_by_sentences(
        text: str, 
        sentences_per_chunk: int = 5,
        overlap_sentences: int = 1
    ) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º.
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            sentences_per_chunk: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —á–∞–Ω–∫–µ
            overlap_sentences: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
        """
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Ç–æ—á–∫–∞–º (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        chunks = []
        start = 0
        
        while start < len(sentences):
            end = min(start + sentences_per_chunk, len(sentences))
            chunk = ' '.join(sentences[start:end])
            chunks.append(chunk)
            
            start = end - overlap_sentences
            if start < 0:
                start = end
        
        return chunks
    
    @staticmethod
    def chunk_by_paragraphs(text: str, min_chunk_size: int = 100) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º (–¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏).
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            min_chunk_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
        """
        paragraphs = text.split('\n\n')
        paragraphs = [p.strip() for p in paragraphs if p.strip()]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) < min_chunk_size * 3:
                current_chunk += "\n\n" + para if current_chunk else para
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = para
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    @staticmethod
    def chunk_with_metadata(
        text: str,
        source: str,
        chunk_size: int = 1000,
        overlap: int = 200
    ) -> List[Dict]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ –∫–∞–∂–¥–æ–º—É —á–∞–Ω–∫—É.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        chunks = TextChunker.chunk_by_chars(text, chunk_size, overlap)
        
        return [
            {
                "text": chunk,
                "metadata": {
                    "source": source,
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "char_start": sum(len(c) for c in chunks[:i]),
                }
            }
            for i, chunk in enumerate(chunks)
        ]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    long_text = """
    Python ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π 
    —Å—Ç—Ä–æ–≥–æ–π —Ç–∏–ø–∏–∑–∞—Ü–∏–µ–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é. –û–Ω –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ 
    –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞, —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –∫–æ–¥–∞ –∏ –µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.

    –°–∏–Ω—Ç–∞–∫—Å–∏—Å —è–¥—Ä–∞ Python –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–µ–Ω. –í —Ç–æ –∂–µ –≤—Ä–µ–º—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 
    –≤–∫–ª—é—á–∞–µ—Ç –±–æ–ª—å—à–æ–π –æ–±—ä—ë–º –ø–æ–ª–µ–∑–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π. Python –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–µ, 
    –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ, –∏–º–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –∏ –∞—Å–ø–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ 
    –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ.

    –û—Å–Ω–æ–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —á–µ—Ä—Ç—ã ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è —Ç–∏–ø–∏–∑–∞—Ü–∏—è, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 
    –ø–∞–º—è—Ç—å—é, –ø–æ–ª–Ω–∞—è –∏–Ω—Ç—Ä–æ—Å–ø–µ–∫—Ü–∏—è, –º–µ—Ö–∞–Ω–∏–∑–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã—Ö 
    –≤—ã—á–∏—Å–ª–µ–Ω–∏–π —Å –≥–ª–æ–±–∞–ª—å–Ω–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä–∞ (GIL).

    Python –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–∑–≤–∏–≤–∞–µ—Ç—Å—è –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–∞–∫–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö –∫–∞–∫ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞, 
    –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Å–∫—Ä–∏–ø—Ç–∏–Ω–≥, –Ω–∞—É—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è.
    """
    
    chunker = TextChunker()
    
    print("="*60)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø CHUNKING")
    print("="*60)
    
    # –ü–æ —Å–∏–º–≤–æ–ª–∞–º
    print("\nüìä Chunking –ø–æ —Å–∏–º–≤–æ–ª–∞–º (500 —Å–∏–º–≤–æ–ª–æ–≤, overlap 100):")
    chunks = chunker.chunk_by_chars(long_text, 500, 100)
    for i, chunk in enumerate(chunks):
        print(f"\n  –ß–∞–Ω–∫ {i+1} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤):")
        print(f"    {chunk[:100]}...")
    
    # –ü–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º
    print("\nüìä Chunking –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):")
    chunks = chunker.chunk_by_sentences(long_text, 3, 1)
    for i, chunk in enumerate(chunks):
        print(f"\n  –ß–∞–Ω–∫ {i+1}:")
        print(f"    {chunk[:100]}...")
    
    # –° –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    print("\nüìä Chunking —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:")
    chunks = chunker.chunk_with_metadata(long_text, "python_intro.txt", 400, 50)
    for chunk in chunks:
        print(f"\n  –ß–∞–Ω–∫ {chunk['metadata']['chunk_index']+1}:")
        print(f"    –ò—Å—Ç–æ—á–Ω–∏–∫: {chunk['metadata']['source']}")
        print(f"    –¢–µ–∫—Å—Ç: {chunk['text'][:80]}...")
```

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è

### üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å

**–ó–∞–¥–∞–Ω–∏–µ 1: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤**

1. –ü–æ–ª—É—á–∏—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è 10 —Å–ª–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π:
   - 3 —Å–ª–æ–≤–∞ –ø—Ä–æ –µ–¥—É
   - 3 —Å–ª–æ–≤–∞ –ø—Ä–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
   - 4 —Å–ª—É—á–∞–π–Ω—ã—Ö —Å–ª–æ–≤–∞
2. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–∞—Ç—Ä–∏—Ü—É —Å—Ö–æ–¥—Å—Ç–≤–∞
3. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–º–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç–æ–º)

**–ó–∞–¥–∞–Ω–∏–µ 2: –ü–µ—Ä–≤–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞**

1. –°–æ–∑–¥–∞–π—Ç–µ SimpleVectorDB
2. –î–æ–±–∞–≤—å—Ç–µ 20 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ `sample_docs.txt`
3. –í—ã–ø–æ–ª–Ω–∏—Ç–µ 5 –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
4. –û—Ü–µ–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### üü° –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å

**–ó–∞–¥–∞–Ω–∏–µ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π chunking**

1. –í–æ–∑—å–º–∏—Ç–µ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (1000+ —Å–ª–æ–≤)
2. –†–∞–∑–±–µ–π—Ç–µ –µ–≥–æ —Ç—Ä–µ–º—è —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏:
   - –ü–æ —Å–∏–º–≤–æ–ª–∞–º (500 —Å–∏–º–≤–æ–ª–æ–≤)
   - –ü–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
   - –ü–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º
3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ø–æ—Å–æ–±–∞:
   - –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–π—Ç–µ —á–∞–Ω–∫–∏
   - –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
   - –°—Ä–∞–≤–Ω–∏—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

**–ó–∞–¥–∞–Ω–∏–µ 4: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π**

1. –°–æ–∑–¥–∞–π—Ç–µ –±–∞–∑—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –∞–≤—Ç–æ—Ä, –¥–∞—Ç–∞)
2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ 10 –∑–∞–ø—Ä–æ—Å–∞—Ö —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏

### üî¥ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å

**–ó–∞–¥–∞–Ω–∏–µ 5: –ü–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ PDF**

1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ PDF –¥–æ–∫—É–º–µ–Ω—Ç (—É—á–µ–±–Ω–∏–∫, —Å—Ç–∞—Ç—å—è)
2. –ò–∑–≤–ª–µ–∫–∏—Ç–µ —Ç–µ–∫—Å—Ç
3. –†–∞–∑–±–µ–π—Ç–µ –Ω–∞ —á–∞–Ω–∫–∏ —Å overlap
4. –°–æ–∑–¥–∞–π—Ç–µ –ø–æ–∏—Å–∫–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É —Å:
   - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º
   - –ü–æ–∫–∞–∑–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞)
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º/–∑–∞–≥—Ä—É–∑–∫–æ–π –∏–Ω–¥–µ–∫—Å–∞

**–ó–∞–¥–∞–Ω–∏–µ 6: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫**

1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –ø–æ–∏—Å–∫ –Ω–∞:
   - FAISS
   - Chroma
2. –°—Ä–∞–≤–Ω–∏—Ç–µ –ø–æ:
   - –°–∫–æ—Ä–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
   - –°–∫–æ—Ä–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞
   - –ö–∞—á–µ—Å—Ç–≤—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
   - –£–¥–æ–±—Å—Ç–≤—É API
3. –û—Ñ–æ—Ä–º–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ—Ç—á—ë—Ç

## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã

1. **–ß—Ç–æ —Ç–∞–∫–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏?**
   <details>
   <summary>–û—Ç–≤–µ—Ç</summary>
   –≠–º–±–µ–¥–¥–∏–Ω–≥ ‚Äî —ç—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–∏–¥–µ –≤–µ–∫—Ç–æ—Ä–∞ —á–∏—Å–µ–ª, –≥–¥–µ –ø–æ—Ö–æ–∂–∏–µ –ø–æ —Å–º—ã—Å–ª—É —Ç–µ–∫—Å—Ç—ã –∏–º–µ—é—Ç –±–ª–∏–∑–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã. –ö–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ –∫–∞—Ä—Ç–µ, —Ç–æ–ª—å–∫–æ –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å–º—ã—Å–ª–æ–≤.
   </details>

2. **–ü–æ—á–µ–º—É —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ª—É—á—à–µ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º?**
   <details>
   <summary>–û—Ç–≤–µ—Ç</summary>
   –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ–Ω–∏–º–∞–µ—Ç —Å–º—ã—Å–ª, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤. "–ö—É–ø–∏—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω" –∏ "–ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏ —Å–º–∞—Ä—Ç—Ñ–æ–Ω" –æ–∑–Ω–∞—á–∞—é—Ç –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ, –Ω–æ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ —Å–ª–æ–≤–∞. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É–ª–∞–≤–ª–∏–≤–∞—é—Ç —ç—Ç–æ —Å—Ö–æ–¥—Å—Ç–≤–æ.
   </details>

3. **–ß—Ç–æ —Ç–∞–∫–æ–µ chunking –∏ –∑–∞—á–µ–º –æ–Ω –Ω—É–∂–µ–Ω?**
   <details>
   <summary>–û—Ç–≤–µ—Ç</summary>
   Chunking ‚Äî —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –Ω–µ–±–æ–ª—å—à–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (200-500 —Ç–æ–∫–µ–Ω–æ–≤). –ù—É–∂–µ–Ω –ø–æ—Ç–æ–º—É —á—Ç–æ: 1) —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö, 2) –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –Ω—É–∂–µ–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –∞ –Ω–µ –≤–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç.
   </details>

4. **–ß–µ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è FAISS –æ—Ç Chroma?**
   <details>
   <summary>–û—Ç–≤–µ—Ç</summary>
   FAISS ‚Äî –Ω–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –æ—Ç Meta, –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç —Ä—É—á–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏. Chroma ‚Äî –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Å —É–¥–æ–±–Ω—ã–º API, –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ.
   </details>

5. **–ö–∞–∫ –∏–∑–º–µ—Ä–∏—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤?**
   <details>
   <summary>–û—Ç–≤–µ—Ç</summary>
   –û–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ‚Äî –∫–æ—Å–∏–Ω—É—Å —É–≥–ª–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏. –ó–Ω–∞—á–µ–Ω–∏—è –æ—Ç -1 (–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã–µ) –¥–æ 1 (–∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ). –î–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —ç—Ç–æ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ —Å–∫–∞–ª—è—Ä–Ω–æ–º—É –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—é.
   </details>

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ —É—Ä–æ–∫–∞

### –ß—Ç–æ –º—ã –∏–∑—É—á–∏–ª–∏

- **–≠–º–±–µ–¥–¥–∏–Ω–≥–∏**: –∫–∞–∫ —Ç–µ–∫—Å—Ç –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ –≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª
- **–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤**: —á–µ—Ä–µ–∑ API —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- **–í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã**: FAISS –∏ Chroma –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ–∏—Å–∫–∞
- **–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫**: –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–º—ã—Å–ª—É
- **Chunking**: —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞

### –°–≤—è–∑—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —É—Ä–æ–∫–æ–º

–í —É—Ä–æ–∫–µ 1 –º—ã —É–∑–Ω–∞–ª–∏, —á—Ç–æ RAG —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ Retriever –∏ Generator. –°–µ–≥–æ–¥–Ω—è –º—ã –ø–æ—Å—Ç—Ä–æ–∏–ª–∏ **Retriever** ‚Äî —Å–∏—Å—Ç–µ–º—É, –∫–æ—Ç–æ—Ä–∞—è:
- –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä—ã
- –•—Ä–∞–Ω–∏—Ç –∏—Ö –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –±–∞–∑–µ
- –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É

### –ß—Ç–æ –¥–∞–ª—å—à–µ

–í —Å–ª–µ–¥—É—é—â–µ–º —É—Ä–æ–∫–µ **"–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"** –º—ã:
- –°–æ–µ–¥–∏–Ω–∏–º Retriever —Å LLM (Generator)
- –°–æ–∑–¥–∞–¥–∏–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π RAG pipeline
- –ü–æ—Å—Ç—Ä–æ–∏–º —Ä–∞–±–æ—Ç–∞—é—â–µ–≥–æ QA-–±–æ—Ç–∞

### –í–∞—à –ø—Ä–æ–≥—Ä–µ—Å—Å

üéØ **–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞!** –¢–µ–ø–µ—Ä—å –≤—ã —É–º–µ–µ—Ç–µ:
- ‚úÖ –ü–æ–ª—É—á–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- ‚úÖ –°–æ–∑–¥–∞–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –í—ã–ø–æ–ª–Ω—è—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
- ‚úÖ –†–∞–∑–±–∏–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–∞ —á–∞–Ω–∫–∏

**–ì–æ—Ç–æ–≤—ã —Å–æ–±—Ä–∞—Ç—å –≤—Å—ë –≤–º–µ—Å—Ç–µ?** –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ [–£—Ä–æ–∫—É 3: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏](lesson_3_rag_pipeline.md)!

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [FAISS Wiki](https://github.com/facebookresearch/faiss/wiki)
- [Chroma Documentation](https://docs.trychroma.com/)

### –°—Ç–∞—Ç—å–∏:
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [Efficient and Robust Approximate Nearest Neighbor Search](https://arxiv.org/abs/1603.09320)

### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
- [sentence-transformers](https://www.sbert.net/) ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
- [Qdrant](https://qdrant.tech/) ‚Äî production –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞
- [Pinecone](https://www.pinecone.io/) ‚Äî managed –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞

